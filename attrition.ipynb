{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "alIIEHibGc3M"
   },
   "source": [
    "## Part 1: Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (2.1.4)\n",
      "Requirement already satisfied: numpy<2,>=1.22.4 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip3 install sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "id": "6eDUJ4NtGc3P",
    "outputId": "2480098c-135c-4cbf-9552-018494ee8ff5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>BusinessTravel</th>\n",
       "      <th>Department</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EducationField</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>...</th>\n",
       "      <th>PerformanceRating</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>StockOptionLevel</th>\n",
       "      <th>TotalWorkingYears</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsAtCompany</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Sales</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Frequently</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Life Sciences</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>No</td>\n",
       "      <td>Travel_Rarely</td>\n",
       "      <td>Research &amp; Development</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Medical</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Attrition     BusinessTravel              Department  DistanceFromHome  \\\n",
       "0   41       Yes      Travel_Rarely                   Sales                 1   \n",
       "1   49        No  Travel_Frequently  Research & Development                 8   \n",
       "2   37       Yes      Travel_Rarely  Research & Development                 2   \n",
       "3   33        No  Travel_Frequently  Research & Development                 3   \n",
       "4   27        No      Travel_Rarely  Research & Development                 2   \n",
       "\n",
       "   Education EducationField  EnvironmentSatisfaction  HourlyRate  \\\n",
       "0          2  Life Sciences                        2          94   \n",
       "1          1  Life Sciences                        3          61   \n",
       "2          2          Other                        4          92   \n",
       "3          4  Life Sciences                        4          56   \n",
       "4          1        Medical                        1          40   \n",
       "\n",
       "   JobInvolvement  ...  PerformanceRating RelationshipSatisfaction  \\\n",
       "0               3  ...                  3                        1   \n",
       "1               2  ...                  4                        4   \n",
       "2               2  ...                  3                        2   \n",
       "3               3  ...                  3                        3   \n",
       "4               3  ...                  3                        4   \n",
       "\n",
       "   StockOptionLevel TotalWorkingYears  TrainingTimesLastYear WorkLifeBalance  \\\n",
       "0                 0                 8                      0               1   \n",
       "1                 1                10                      3               3   \n",
       "2                 0                 7                      3               3   \n",
       "3                 0                 8                      3               3   \n",
       "4                 1                 6                      3               3   \n",
       "\n",
       "   YearsAtCompany  YearsInCurrentRole  YearsSinceLastPromotion  \\\n",
       "0               6                   4                        0   \n",
       "1              10                   7                        1   \n",
       "2               0                   0                        0   \n",
       "3               8                   7                        3   \n",
       "4               2                   2                        2   \n",
       "\n",
       "   YearsWithCurrManager  \n",
       "0                     5  \n",
       "1                     7  \n",
       "2                     0  \n",
       "3                     0  \n",
       "4                     2  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#  Import and read the attrition data\n",
    "attrition_df = pd.read_csv('https://static.bc-edx.com/ai/ail-v-1-0/m19/lms/datasets/attrition.csv')\n",
    "attrition_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g22aQSY4Gc3Q",
    "outputId": "1f5c13c1-b981-4e40-a7ed-dd3fe6f1b81e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                         43\n",
       "Attrition                    2\n",
       "BusinessTravel               3\n",
       "Department                   3\n",
       "DistanceFromHome            29\n",
       "Education                    5\n",
       "EducationField               6\n",
       "EnvironmentSatisfaction      4\n",
       "HourlyRate                  71\n",
       "JobInvolvement               4\n",
       "JobLevel                     5\n",
       "JobRole                      9\n",
       "JobSatisfaction              4\n",
       "MaritalStatus                3\n",
       "NumCompaniesWorked          10\n",
       "OverTime                     2\n",
       "PercentSalaryHike           15\n",
       "PerformanceRating            2\n",
       "RelationshipSatisfaction     4\n",
       "StockOptionLevel             4\n",
       "TotalWorkingYears           40\n",
       "TrainingTimesLastYear        7\n",
       "WorkLifeBalance              4\n",
       "YearsAtCompany              37\n",
       "YearsInCurrentRole          19\n",
       "YearsSinceLastPromotion     16\n",
       "YearsWithCurrManager        18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "attrition_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "50vMgBEnJbfM"
   },
   "outputs": [],
   "source": [
    "# Create y_df with the Attrition and Department columns\n",
    "y_df = attrition_df[['Attrition', 'Department']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Virka0zLGc3R",
    "outputId": "dd5aee3a-9458-4ba6-e857-1b234de40915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                         int64\n",
      "BusinessTravel             object\n",
      "DistanceFromHome            int64\n",
      "Education                   int64\n",
      "EducationField             object\n",
      "EnvironmentSatisfaction     int64\n",
      "HourlyRate                  int64\n",
      "JobInvolvement              int64\n",
      "JobLevel                    int64\n",
      "JobRole                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create a list of at least 10 column names to use as X data\n",
    "X_columns = attrition_df.columns.difference(['Attrition', 'Department']).tolist()[:10]\n",
    "\n",
    "# Create X_df using your selected columns\n",
    "X_df = attrition_df[X_columns]\n",
    "\n",
    "# Show the data types for X_df\n",
    "print(X_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "KaJfdOGUMHMR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (1029, 10)\n",
      "Testing set size: (441, 10)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Optionally, print the sizes of the train and test datasets to verify\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Testing set size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYubUJqiLCSp",
    "outputId": "53f31721-571c-4c94-d13e-25a715749593"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ColumnTransformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m numeric_columns \u001b[38;5;241m=\u001b[39m X_df\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a transformer for numerical data (optional, here just a placeholder)\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# If you want to scale or normalize numerical columns, you could add transformers here.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Create a ColumnTransformer to apply transformations to the respective column types\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m transformer \u001b[38;5;241m=\u001b[39m \u001b[43mColumnTransformer\u001b[49m(\n\u001b[1;32m     12\u001b[0m     transformers\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     13\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m'\u001b[39m, numeric_columns),  \u001b[38;5;66;03m# Applies no transformation to numeric columns\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, OneHotEncoder(), categorical_columns)  \u001b[38;5;66;03m# Applies OneHotEncoder to categorical columns\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     ])\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Fit and transform the X data\u001b[39;00m\n\u001b[1;32m     18\u001b[0m X_transformed \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X_df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ColumnTransformer' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert your X data to numeric data types however you see fit\n",
    "# Add new code cells as necessary\n",
    "# Identify categorical columns - This is an example and might need adjustment based on actual data\n",
    "categorical_columns = X_df.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_columns = X_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Create a transformer for numerical data (optional, here just a placeholder)\n",
    "# If you want to scale or normalize numerical columns, you could add transformers here.\n",
    "\n",
    "# Create a ColumnTransformer to apply transformations to the respective column types\n",
    "transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', numeric_columns),  # Applies no transformation to numeric columns\n",
    "        ('cat', OneHotEncoder(), categorical_columns)  # Applies OneHotEncoder to categorical columns\n",
    "    ])\n",
    "\n",
    "# Fit and transform the X data\n",
    "X_transformed = transformer.fit_transform(X_df)\n",
    "\n",
    "# Optionally, convert the output back to a DataFrame (useful for checking results and further processing)\n",
    "X_transformed_df = pd.DataFrame(X_transformed, columns=transformer.get_feature_names_out())\n",
    "\n",
    "# Show the transformed DataFrame\n",
    "print(X_transformed_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWA-aIA5Gc3T"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming X_train and X_test have been previously split and contain numeric columns\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler to the training data (only numeric columns if mixed data)\n",
    "scaler.fit(X_train[numeric_columns])\n",
    "\n",
    "# Scale the training and testing data\n",
    "X_train_scaled = scaler.transform(X_train[numeric_columns])\n",
    "X_test_scaled = scaler.transform(X_test[numeric_columns])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-z0Mky8vQSz4",
    "outputId": "debefc85-c20b-48f5-f4d9-91eadd65d36a"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming y_train and y_test have been previously split and include the 'Department' column\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "encoder = OneHotEncoder(sparse=False)  # sparse=False to return a dense array for easier handling\n",
    "\n",
    "# Fit the encoder to the Department column of the training data\n",
    "encoder.fit(y_train[['Department']])\n",
    "\n",
    "# Transform the Department column in both training and testing data\n",
    "y_train_department_encoded = encoder.transform(y_train[['Department']])\n",
    "y_test_department_encoded = encoder.transform(y_test[['Department']])\n",
    "\n",
    "# Optionally, convert these arrays back to DataFrame for easier manipulation and readability\n",
    "department_features = encoder.get_feature_names_out(['Department'])\n",
    "y_train_department_df = pd.DataFrame(y_train_department_encoded, columns=department_features)\n",
    "y_test_department_df = pd.DataFrame(y_test_department_encoded, columns=department_features)\n",
    "\n",
    "# Print the transformed data to verify\n",
    "print(y_train_department_df.head())\n",
    "print(y_test_department_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-G4DSpvFRrk4",
    "outputId": "9842e948-8a55-4b80-8fac-f96714e85589"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OneHotEncoder\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming y_train and y_test have been previously split and include the 'Department' column\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Create a OneHotEncoder instance\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m encoder \u001b[38;5;241m=\u001b[39m \u001b[43mOneHotEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# sparse=False to return a dense array for easier handling\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Fit the encoder to the Department column of the training data\u001b[39;00m\n\u001b[1;32m      9\u001b[0m encoder\u001b[38;5;241m.\u001b[39mfit(y_train[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepartment\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'sparse'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming y_train and y_test have been previously split and include the 'Department' column\n",
    "\n",
    "# Create a OneHotEncoder instance\n",
    "encoder = OneHotEncoder(sparse=False)  # sparse=False to return a dense array for easier handling\n",
    "\n",
    "# Fit the encoder to the Department column of the training data\n",
    "encoder.fit(y_train[['Department']])\n",
    "\n",
    "# Transform the Department column in both training and testing data\n",
    "y_train_department_encoded = encoder.transform(y_train[['Department']])\n",
    "y_test_department_encoded = encoder.transform(y_test[['Department']])\n",
    "\n",
    "# Optionally, convert these arrays back to DataFrame for easier manipulation and readability\n",
    "department_features = encoder.get_feature_names_out(['Department'])\n",
    "y_train_department_df = pd.DataFrame(y_train_department_encoded, columns=department_features)\n",
    "y_test_department_df = pd.DataFrame(y_test_department_encoded, columns=department_features)\n",
    "\n",
    "# Print the transformed data to verify\n",
    "print(y_train_department_df.head())\n",
    "print(y_test_department_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykNmu_WWGc3T"
   },
   "source": [
    "## Create, Compile, and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.16.1-cp39-cp39-macosx_10_15_x86_64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Downloading h5py-3.11.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.3.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from tensorflow) (4.7.1)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.63.0-cp39-cp39-macosx_10_9_universal2.whl.metadata (3.2 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow)\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow)\n",
      "  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.0-cp39-cp39-macosx_10_14_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from tensorflow) (1.26.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow)\n",
      "  Downloading optree-0.11.0-cp39-cp39-macosx_10_9_x86_64.whl.metadata (45 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.5.2)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.17,>=2.16->tensorflow)\n",
      "  Downloading werkzeug-3.0.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from rich->keras>=3.0.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.17,>=2.16->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Downloading tensorflow-2.16.1-cp39-cp39-macosx_10_15_x86_64.whl (259.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.63.0-cp39-cp39-macosx_10_9_universal2.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading h5py-3.11.0-cp39-cp39-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-macosx_10_9_x86_64.whl (26.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp39-cp39-macosx_10_9_universal2.whl (389 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.8/389.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_io_gcs_filesystem-0.37.0-cp39-cp39-macosx_10_14_x86_64.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading wrapt-1.16.0-cp39-cp39-macosx_10_9_x86_64.whl (37 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading werkzeug-3.0.3-py3-none-any.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.3/227.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp39-cp39-macosx_10_9_x86_64.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.2/295.2 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: namex, libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, rich, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.63.0 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 protobuf-4.25.3 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-io-gcs-filesystem-0.37.0 termcolor-2.4.0 werkzeug-3.0.3 wrapt-1.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tensorflow \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "WUptZqmSGc3T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-08 16:35:15.618257: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/cattienle/anaconda3/envs/testmojave/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,360</span> (44.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,360\u001b[0m (44.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,360</span> (44.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,360\u001b[0m (44.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the number of columns in the X training data\n",
    "\n",
    "num_features = X_train_scaled.shape[1]\n",
    "print(\"Number of input features:\", num_features)\n",
    "# Create the input layer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the input layer\n",
    "model.add(Dense(128, activation='relu', input_shape=(num_features,)))\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "\n",
    "# Optionally, add more layers or the output layer depending on your specific problem\n",
    "# For example, for a binary classification problem, you can add:\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "# Create at least two shared layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "JukjTm2yTEqd"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming 'y_train_department_df' has already been created and contains the OneHotEncoded Department data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m num_department_features \u001b[38;5;241m=\u001b[39m \u001b[43mnum_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a branch input specific to the Department data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m department_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(num_department_features,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepartment_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'df'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming 'y_train_department_df' has already been created and contains the OneHotEncoded Department data\n",
    "num_department_features = num_features.df.shape[1]\n",
    "\n",
    "# Create a branch input specific to the Department data\n",
    "department_input = Input(shape=(num_department_features,), name='department_input')\n",
    "\n",
    "# Create a hidden layer for the Department branch\n",
    "department_hidden = Dense(16, activation='relu', name='department_hidden')(department_input)\n",
    "\n",
    "# Create an output layer for the Department branch\n",
    "# Adjust the number of neurons and activation based on the specific needs (e.g., classification, regression)\n",
    "department_output = Dense(10, activation='softmax', name='department_output')(department_hidden)  # Example for a classification with 10 classes\n",
    "\n",
    "# Create a Model for the Department branch\n",
    "department_model = Model(inputs=department_input, outputs=department_output)\n",
    "\n",
    "department_model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9OqhUiOJUBkR"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_train_attrition_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming 'y_train_attrition_df' has already been created and contains the OneHotEncoded Attrition data\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m num_attrition_features \u001b[38;5;241m=\u001b[39m \u001b[43my_train_attrition_df\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Create a branch input specific to the Attrition data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m attrition_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(num_attrition_features,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattrition_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_attrition_df' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming 'y_train_attrition_df' has already been created and contains the OneHotEncoded Attrition data\n",
    "num_attrition_features = y_train_attrition_df.shape[1]\n",
    "\n",
    "# Create a branch input specific to the Attrition data\n",
    "attrition_input = Input(shape=(num_attrition_features,), name='attrition_input')\n",
    "\n",
    "# Create a hidden layer for the Attrition branch\n",
    "attrition_hidden = Dense(16, activation='relu', name='attrition_hidden')(attrition_input)\n",
    "\n",
    "# Create an output layer for the Attrition branch\n",
    "# Assuming binary classification (e.g., attrition yes/no), using 1 neuron with sigmoid activation\n",
    "attrition_output = Dense(1, activation='sigmoid', name='attrition_output')(attrition_hidden)\n",
    "\n",
    "# Create a Model for the Attrition branch\n",
    "attrition_model = Model(inputs=attrition_input, outputs=attrition_output)\n",
    "\n",
    "attrition_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "twmuejdxGc3T",
    "outputId": "25096308-b68b-42e4-e4ea-ae82e97c435a"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_attrition_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming the previous definitions for 'department_model' and 'attrition_model' and their inputs and outputs\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Inputs\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m department_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(\u001b[43mnum_attrition_features\u001b[49m ,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepartment_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m attrition_input \u001b[38;5;241m=\u001b[39m Input(shape\u001b[38;5;241m=\u001b[39m(num_attrition_features ,), name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattrition_input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Hidden layers\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_attrition_features' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming the previous definitions for 'department_model' and 'attrition_model' and their inputs and outputs\n",
    "\n",
    "# Inputs\n",
    "department_input = Input(shape=(num_attrition_features ,), name='department_input')\n",
    "attrition_input = Input(shape=(num_attrition_features ,), name='attrition_input')\n",
    "\n",
    "# Hidden layers\n",
    "department_hidden = Dense(16, activation='relu', name='department_hidden')(department_input)\n",
    "attrition_hidden = Dense(16, activation='relu', name='attrition_hidden')(attrition_input)\n",
    "\n",
    "# Outputs\n",
    "department_output = Dense(10, activation='softmax', name='department_output')(department_hidden)\n",
    "attrition_output = Dense(1, activation='sigmoid', name='attrition_output')(attrition_hidden)\n",
    "\n",
    "# Combine outputs\n",
    "combined_output = concatenate([department_output, attrition_output])\n",
    "\n",
    "# Final model\n",
    "final_output = Dense(5, activation='softmax', name='final_output')(combined_output)  # Example setup for a final layer\n",
    "\n",
    "model = Model(inputs=[department_input, attrition_input], outputs=[final_output])\n",
    "\n",
    "### Step 2: Compile the model\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy',  # Adjust based on the actual tasks and number of outputs\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "### Step 3: Summarize the model\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c8oGy0dpGc3U",
    "outputId": "cc667d43-28cf-42d4-d719-c2bc02888d30"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VsMoaQlgGc3U",
    "outputId": "1bd4e601-e964-4abc-ad83-aeecf6b696be"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model with the testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZlCtlHi0Vt54",
    "outputId": "bc21ef3e-80c2-4b38-9c29-79515bc23dec"
   },
   "outputs": [],
   "source": [
    "# Print the accuracy for both department and attrition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eGSyfsZfWOQM"
   },
   "source": [
    "# Summary\n",
    "\n",
    "In the provided space below, briefly answer the following questions.\n",
    "\n",
    "1. Is accuracy the best metric to use on this data? Why or why not?\n",
    "\n",
    "2. What activation functions did you choose for your output layers, and why?\n",
    "\n",
    "3. Can you name a few ways that this model might be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pi9SLpFnWvbF"
   },
   "source": [
    "YOUR ANSWERS HERE\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
